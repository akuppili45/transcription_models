{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c341fbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20230314.tar.gz (792 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.9/792.9 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: more-itertools in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (8.10.0)\n",
      "Requirement already satisfied: tqdm in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (4.62.3)\n",
      "Requirement already satisfied: torch in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (1.10.2)\n",
      "Collecting ffmpeg-python==0.2.0\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (1.20.3)\n",
      "Collecting tiktoken==0.3.1\n",
      "  Downloading tiktoken-0.3.1-cp39-cp39-macosx_10_9_x86_64.whl (735 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.3/735.3 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (0.54.1)\n",
      "Requirement already satisfied: future in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from tiktoken==0.3.1->openai-whisper) (2.26.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from tiktoken==0.3.1->openai-whisper) (2023.6.3)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from numba->openai-whisper) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from numba->openai-whisper) (58.0.4)\n",
      "Requirement already satisfied: typing_extensions in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from torch->openai-whisper) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2021.10.8)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796900 sha256=31ea06bdeeb41693a9e1506e9e619b13188758c26a5de6369fc099756b854802\n",
      "  Stored in directory: /Users/adityakuppili/Library/Caches/pip/wheels/c4/85/e6/0bb9507b8e4f3f6d9c6dcf318bc3514739430375aa8e9eaf5b\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: ffmpeg-python, tiktoken, openai-whisper\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.4.0\n",
      "    Uninstalling tiktoken-0.4.0:\n",
      "      Successfully uninstalled tiktoken-0.4.0\n",
      "Successfully installed ffmpeg-python-0.2.0 openai-whisper-20230314 tiktoken-0.3.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama_hub\n",
      "  Downloading llama_hub-0.0.15-py3-none-any.whl (887 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.0/887.0 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: llama-index>=0.6.9 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama_hub) (0.6.13)\n",
      "Collecting html2text\n",
      "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: psutil in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama_hub) (5.8.0)\n",
      "Collecting retrying\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Collecting atlassian-python-api\n",
      "  Downloading atlassian-python-api-3.39.0.tar.gz (157 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.5/157.5 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (8.2.2)\n",
      "Requirement already satisfied: pandas in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (1.3.4)\n",
      "Requirement already satisfied: urllib3<2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (1.26.7)\n",
      "Requirement already satisfied: typing-extensions==4.5.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (4.5.0)\n",
      "Requirement already satisfied: numpy in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (1.20.3)\n",
      "Requirement already satisfied: langchain>=0.0.154 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (0.0.154)\n",
      "Requirement already satisfied: tiktoken in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (0.3.1)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.15 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (2.0.16)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (2023.6.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (0.5.8)\n",
      "Requirement already satisfied: openai>=0.26.4 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (0.27.8)\n",
      "Requirement already satisfied: typing-inspect==0.8.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (0.8.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from typing-inspect==0.8.0->llama-index>=0.6.9->llama_hub) (0.4.3)\n",
      "Requirement already satisfied: oauthlib in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from atlassian-python-api->llama_hub) (3.2.0)\n",
      "Requirement already satisfied: requests in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from atlassian-python-api->llama_hub) (2.26.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from atlassian-python-api->llama_hub) (1.3.1)\n",
      "Collecting deprecated\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: six in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from atlassian-python-api->llama_hub) (1.12.0)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (1.10.9)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (1.2.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (3.8.4)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (2.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (4.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (4.62.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->llama-index>=0.6.9->llama_hub) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->llama-index>=0.6.9->llama_hub) (1.5.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->atlassian-python-api->llama_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->atlassian-python-api->llama_hub) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->atlassian-python-api->llama_hub) (2021.10.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sqlalchemy>=2.0.15->llama-index>=0.6.9->llama_hub) (1.1.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from deprecated->atlassian-python-api->llama_hub) (1.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index>=0.6.9->llama_hub) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index>=0.6.9->llama_hub) (2021.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from tiktoken->llama-index>=0.6.9->llama_hub) (2023.6.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (21.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index>=0.6.9->llama_hub) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index>=0.6.9->llama_hub) (3.0.4)\n",
      "Building wheels for collected packages: atlassian-python-api\n",
      "  Building wheel for atlassian-python-api (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for atlassian-python-api: filename=atlassian_python_api-3.39.0-py3-none-any.whl size=163448 sha256=29ca764d78acfd9aa72916a53ae1e3ac4e1a0cfb092c64e0e4612e81821d014f\n",
      "  Stored in directory: /Users/adityakuppili/Library/Caches/pip/wheels/90/96/41/e5ccd996d254db16c3977db057ea9e1ee4e999d4ae7a40d6da\n",
      "Successfully built atlassian-python-api\n",
      "Installing collected packages: retrying, html2text, deprecated, atlassian-python-api, llama_hub\n",
      "Successfully installed atlassian-python-api-3.39.0 deprecated-1.2.14 html2text-2020.1.16 llama_hub-0.0.15 retrying-1.3.4\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformers\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-macosx_10_11_x86_64.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.1-cp39-cp39-macosx_10_11_x86_64.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.8/400.8 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: fsspec in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement huggingface-cli (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for huggingface-cli\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (1.10.2)\n",
      "Requirement already satisfied: typing_extensions in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerate\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (5.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (1.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (21.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (1.10.2)\n",
      "Requirement already satisfied: pyyaml in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->accelerate) (3.0.4)\n",
      "Requirement already satisfied: typing_extensions in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.21.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting datasets\n",
      "  Downloading datasets-2.14.1-py3-none-any.whl (492 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.4/492.4 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: aiohttp in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py39-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.26.0)\n",
      "Collecting dill<0.3.8,>=0.3.0\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.3.4)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-macosx_10_9_x86_64.whl (35 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.20.3)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-12.0.1-cp39-cp39-macosx_10_14_x86_64.whl (24.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.12.0)\n",
      "Installing collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
      "Successfully installed datasets-2.14.1 dill-0.3.7 multiprocess-0.70.15 pyarrow-12.0.1 xxhash-3.2.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-whisper\n",
    "!pip install llama_hub\n",
    "!pip install transformers\n",
    "!pip install huggingface-cli\n",
    "!pip install torch\n",
    "!pip install accelerate\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "979916d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fc557a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd33c07aa2d441592906a4ce78f5ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8bd0df18a14851874a3ee1e223c385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/6.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c283aec9dc4ab9a2ff5b407b191f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/3.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6dca88c06524c47a32d2b4a65a95f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/800 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edcdf61d2e54e70afb7201953ba43e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5150076a05435f89fe41a1cf42384b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74450ce8d724fe48bf074888c05ba29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94cff8975c4d4acd92c5f377b43b7b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)main/normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d95c843bd694b2080aa1a52ae27dd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c414c2189bfd4d659828be1bb01c8368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf991b0573e4df8a6c7bc6295785138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transform_pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c19753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chetan_BPO Ops Consultant_Recruiter Manjiri.mp3\r\n",
      "Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad5add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \" Hello Hello, am I talking to Shripal? Yes, speaking Shripal, I am Manjiri, I am calling from EASEST I got your application for the BPO position with us couple of days ago Ok So, good time to talk right now? Ya, ma'am Right Shripal, so like I said I am calling from EASEST We are located in Pondek, Injayawadi, Phase 1, Cubix IT Park and this is a work from Injayawadi location So, would that work for you? Ya Ok, great\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_pipe('./Chetan_BPO Ops Consultant_Recruiter Manjiri.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba3d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3dd3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub\n",
    "\n",
    "# Load the mp3 file\n",
    "song = pydub.AudioSegment.from_mp3(\"Chetan_BPO Ops Consultant_Recruiter Manjiri.mp3\")\n",
    "\n",
    "# Get the duration of the song\n",
    "duration = song.duration_seconds\n",
    "\n",
    "# Calculate the number of chunks\n",
    "num_chunks = int(duration / 15)\n",
    "\n",
    "# Create a list of chunks\n",
    "chunks = []\n",
    "for i in range(num_chunks):\n",
    "    start = i * 15000\n",
    "    end = min((i + 1) * 15000, duration * 1000)\n",
    "#     print(transform_pipe(np.array(song[start:end].get_array_of_samples())))\n",
    "    chunks.append(song[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c60e3d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x7f7a6ff33880>,\n",
       " <pydub.audio_segment.AudioSegment at 0x7f793ffc6c10>,\n",
       " <pydub.audio_segment.AudioSegment at 0x7f793ffc6a90>,\n",
       " <pydub.audio_segment.AudioSegment at 0x7f793ffc6b80>,\n",
       " <pydub.audio_segment.AudioSegment at 0x7f793ffc6dc0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x7f793ffc6e80>,\n",
       " <pydub.audio_segment.AudioSegment at 0x7f793ffc69a0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x7f793ffc60a0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x7f793ffc69d0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d3ceb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(\"chunk_{}.mp3\".format(i), format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49476668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello, I am talking to Shripal. Shripal, I am Manjiri. I am calling from E-Zest. I got your application for the BPO position with us couple of days ago. So good time to talk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " right now? Yeah ma'am. Right Shipal, so like I said I am calling from EZest, we are located in Pondek, Injiawadi, Phase 1, Cubix IT Park and this is a work from your location so we would like to work for you. Yeah. Okay, great so we are\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " we are actually a technical services delivery company but we are also running a BPO in the travel domain for an international travel domain client basically so it will be like a voice process and international process kind of a thing so how much can I notice or overall experience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I have overall experience of 4.3 years in non-voice process international non-voice process chat and email not in voice process okay but you are comfortable going for voice right?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yeah, I don't have any issues. And how about your excel skills? How would you rate yourself on a scale of 1 to 10? 10 being the highest? 6. 6 to 7. And you are aware about VLOOKUP, HLOOKUP, PIVOT?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No, I am ready to learn it. As of now I don't have any work on excel. No work on excel? Yeah. Okay, but maybe you can learn that and come before the interview, right?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it will take you hardly like an hour to learn it. Yeah, sure. Yeah, so you can prep for that, right? So I'll put it as like basic awareness at least. Okay. Yeah. So doing that.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ok how about your CTC current and expected? I have current CTC of 4.90 and I am expecting 40% increase in that\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " actually going with a budget of 4.5 to 5 lakhs maximum. No ma'am I am currently working at 5. Yeah so then I will need 40% higher\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(chunks)):\n",
    "    transform_pipe_res = transform_pipe(\"./chunk_{}.mp3\".format(i))\n",
    "#     topic_pipe_res = topic_pipe(transform_pipe_res['text'])\n",
    "    print(transform_pipe_res['text'])\n",
    "#     print(topic_pipe_res['whatever'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27efd06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143.544\n"
     ]
    }
   ],
   "source": [
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b41f8e",
   "metadata": {},
   "source": [
    "# Broke chunking/modeling down into functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c973b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertopic in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (0.15.0)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (0.5.3)\n",
      "Requirement already satisfied: hdbscan>=0.8.29 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (0.8.33)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (4.62.3)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (5.15.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (1.20.3)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (0.24.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (1.7.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (1.1.0)\n",
      "Requirement already satisfied: cython<3,>=0.27 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (0.29.24)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2021.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (8.2.2)\n",
      "Requirement already satisfied: packaging in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (21.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (2.2.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.99)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (1.10.2)\n",
      "Requirement already satisfied: torchvision in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.11.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.16.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.31.0)\n",
      "Requirement already satisfied: nltk in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (3.6.5)\n",
      "Requirement already satisfied: numba>=0.49 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.54.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.10)\n",
      "Requirement already satisfied: requests in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.26.0)\n",
      "Requirement already satisfied: filelock in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: setuptools in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.37.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from packaging->plotly>=4.7.0->bertopic) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.1.5->bertopic) (1.12.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.13.3)\n",
      "Requirement already satisfied: click in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (8.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2021.10.8)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23a40b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "topic_model = BERTopic.load(\"davanstrien/chat_topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af6c00a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(text):\n",
    "    topic, prob = topic_model.transform(text)\n",
    "    return topic_model.get_topic(topic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9856f807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0882c8b7844eac9a61258fa531f376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[['chess', 0.531777560710907],\n",
       " ['chessboard', 0.503699779510498],\n",
       " ['practice', 0.35574236512184143],\n",
       " ['strategy', 0.34541815519332886],\n",
       " ['learn', 0.34507590532302856],\n",
       " ['pawn', 0.30584800243377686],\n",
       " ['board', 0.3043401837348938],\n",
       " ['pawns', 0.28188765048980713],\n",
       " ['play', 0.2593632936477661],\n",
       " ['decks', 0.24280010163784027]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topics(\"checkmate is when you win at chess.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0b3eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns array of transcriptions for each chunk\n",
    "def get_transcriptions(model, chunks):\n",
    "    start_time = time.time()\n",
    "    transform_pipe = pipeline(\"automatic-speech-recognition\", model=model)\n",
    "    transcriptions = []\n",
    "    for i in range(len(chunks)):\n",
    "        transform_pipe_res = transform_pipe(\"./chunk_{}.mp3\".format(i))\n",
    "        transcriptions.append((transform_pipe_res['text'], get_topics(transform_pipe_res['text'])))\n",
    "    end_time = time.time()\n",
    "    return transcriptions, end_time - start_time\n",
    "\n",
    "def getChunks(file):\n",
    "    chunks = []\n",
    "    audio = pydub.AudioSegment.from_mp3(file)\n",
    "    duration = audio.duration_seconds\n",
    "    num_chunks = int(duration / 15)\n",
    "    # Create a list of chunks\n",
    "    chunks = []\n",
    "    for i in range(num_chunks):\n",
    "        start = i * 15000\n",
    "        end = min((i + 1) * 15000, duration * 1000)\n",
    "        chunks.append(song[start:end])\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk.export(\"chunk_{}.mp3\".format(i), format=\"mp3\")\n",
    "    return chunks\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b426ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = getChunks('./Chetan_BPO Ops Consultant_Recruiter Manjiri.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5182d025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello, I am talking to Shripal. Shripal, I am Manjiri. I am calling from E-Zest. I got your application for the BPO position with us couple of days ago. So good time to talk.\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      " right now? Yeah ma'am. Right Shipal, so like I said I am calling from EZest, we are located in Pondek, Injiawadi, Phase 1, Cubix IT Park and this is a work from your location so we would like to work for you. Yeah. Okay, great so we are\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      " we are actually a technical services delivery company but we are also running a BPO in the travel domain for an international travel domain client basically so it will be like a voice process and international process kind of a thing so how much can I notice or overall experience\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      " I have overall experience of 4.3 years in non-voice process international non-voice process chat and email not in voice process okay but you are comfortable going for voice right?\n",
      "Topics: [['openai', 0.4242607653141022], ['ai', 0.42098575830459595], ['chatgpt', 0.37633663415908813], ['assistant', 0.29333215951919556], ['language', 0.2651599943637848], ['robot', 0.2454492151737213], ['neural', 0.19960856437683105], ['text', 0.19918669760227203], ['learning', 0.19329103827476501], ['intelligence', 0.19080281257629395]]\n",
      "\n",
      " Yeah, I don't have any issues. And how about your excel skills? How would you rate yourself on a scale of 1 to 10? 10 being the highest? 6. 6 to 7. And you are aware about VLOOKUP, HLOOKUP, PIVOT?\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      " No, I am ready to learn it. As of now I don't have any work on excel. No work on excel? Yeah. Okay, but maybe you can learn that and come before the interview, right?\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      " it will take you hardly like an hour to learn it. Yeah, sure. Yeah, so you can prep for that, right? So I'll put it as like basic awareness at least. Okay. Yeah. So doing that.\n",
      "Topics: [['openai', 0.4242607653141022], ['ai', 0.42098575830459595], ['chatgpt', 0.37633663415908813], ['assistant', 0.29333215951919556], ['language', 0.2651599943637848], ['robot', 0.2454492151737213], ['neural', 0.19960856437683105], ['text', 0.19918669760227203], ['learning', 0.19329103827476501], ['intelligence', 0.19080281257629395]]\n",
      "\n",
      " ok how about your CTC current and expected? I have current CTC of 4.90 and I am expecting 40% increase in that\n",
      "Topics: [['gpus', 0.5102110505104065], ['gpu', 0.46854785084724426], ['motherboard', 0.4229498505592346], ['cpu', 0.4141690731048584], ['hardware', 0.39848506450653076], ['radeon', 0.3514866828918457], ['geforce', 0.34614378213882446], ['upgrading', 0.3420903980731964], ['nvidia', 0.32911717891693115], ['ryzen', 0.32164013385772705]]\n",
      "\n",
      " actually going with a budget of 4.5 to 5 lakhs maximum. No ma'am I am currently working at 5. Yeah so then I will need 40% higher\n",
      "Topics: [['hvac', 0.39111191034317017], ['remodeling', 0.3354414105415344], ['energy', 0.31473082304000854], ['kwh', 0.3112265467643738], ['housing', 0.30327293276786804], ['efficiency', 0.28826797008514404], ['heating', 0.2839772701263428], ['building', 0.28200939297676086], ['apartment', 0.27025389671325684], ['costs', 0.2518804371356964]]\n",
      "\n",
      "439.4878890514374\n"
     ]
    }
   ],
   "source": [
    "openai_transcriptions, openai_time = get_transcriptions(\"openai/whisper-large-v2\", chunks)\n",
    "for transcription in openai_transcriptions:\n",
    "    print(transcription[0])\n",
    "    print(f'Topics: {transcription[1]}')\n",
    "    print()\n",
    "print(openai_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e0781188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f13033051c440018b0f357e5a5e5470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6542a039ac784dd390f4dd7d68f213a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5a00cb73824168be64679226566e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fa5103c4ee4975b66e20229bb5fe63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98925d5eaedc4545922f3887878a8355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbd239876874b878b891cfa869599fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527c0828627744e6bb84d544216428b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d22f07c919408e8991020ca0dac772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b17d7acc964d01b1950b82e4b27dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "igshrepal an mangery iam calling from eas est i gott ar aplication for the bp o position with us couple of das ago so god taime to tak\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      "solike i said i'm calling from easest we are located in puna ingabarry pased one cubic sity park and this is a work for igabary location soto work for yogra\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      "we are actually a tecnical survise's delivery company but we are also running a bpo in the travel domain for in international travel domain clien vasicalli so itl bi lik a voice process an international process kind of a things amagnagv\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      "mr president i have a overall experience of four oi three years in nonwise process international nonwaise process chat and email not in voice process okay but you are comfortable going for voice\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      "aaa obadar exals kills how bad o rator self on a scale of one to ten ten bein the highestand youare aware about we lookup a loku pia\n",
      "Topics: [['poison', 0.41023242473602295], ['chemicals', 0.2576671838760376], ['powder', 0.25158584117889404], ['turpentine', 0.24298548698425293], ['smoke', 0.23245200514793396], ['acid', 0.21897673606872559], ['asbestos', 0.21767115592956543], ['chimney', 0.21686983108520508], ['naphthalene', 0.21119117736816406], ['fireplace', 0.19657978415489197]]\n",
      "\n",
      "no aor but i'm ready to learn it as  nowi don't avan wr maybe you can lak lawn dt and come before the interview\n",
      "Topics: [['chess', 0.531777560710907], ['chessboard', 0.503699779510498], ['practice', 0.35574236512184143], ['strategy', 0.34541815519332886], ['learn', 0.34507590532302856], ['pawn', 0.30584800243377686], ['board', 0.3043401837348938], ['pawns', 0.28188765048980713], ['play', 0.2593632936477661], ['decks', 0.24280010163784027]]\n",
      "\n",
      "b yo in one ot o itl take you hadly alike a nar tool on itya so you can prape for that rat so oil put it as laike basic awarness at leastg\n",
      "Topics: [['chess', 0.531777560710907], ['chessboard', 0.503699779510498], ['practice', 0.35574236512184143], ['strategy', 0.34541815519332886], ['learn', 0.34507590532302856], ['pawn', 0.30584800243377686], ['board', 0.3043401837348938], ['pawns', 0.28188765048980713], ['play', 0.2593632936477661], ['decks', 0.24280010163784027]]\n",
      "\n",
      "i have carent ctc a fourpint nine zo an aiam exspecting a forty versant incrisein that    s\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "ll ging with a budget of    mai a i  a i am currently working a ia s a  will  a t aca\n",
      "Topics: [['hvac', 0.39111191034317017], ['remodeling', 0.3354414105415344], ['energy', 0.31473082304000854], ['kwh', 0.3112265467643738], ['housing', 0.30327293276786804], ['efficiency', 0.28826797008514404], ['heating', 0.2839772701263428], ['building', 0.28200939297676086], ['apartment', 0.27025389671325684], ['costs', 0.2518804371356964]]\n",
      "\n",
      "207.29747009277344\n"
     ]
    }
   ],
   "source": [
    "mms_transcriptions, mms_time = get_transcriptions(\"facebook/mms-1b-all\", chunks)\n",
    "for transcription in mms_transcriptions:\n",
    "    print(transcription[0])\n",
    "    print(f'Topics: {transcription[1]}')\n",
    "    print()\n",
    "print(mms_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "487c51c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788a91dab8284dceb8a5de05085350a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13558e5b566e41bcb059f66bd44640e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f4b0234e9e45d2ac22d475cfcd835f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90f903c5fb44b0b80e4799da4456616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9869a91fc1784cbe9b5f35c43ac39b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a236f44aa684a5e827b091ee612ac5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fe1f1e37dc4501a052ade32dfb40b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37dcf42b727a4676ae8303742d4d9c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d71cec7d894675859b1a5aab0475bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello, I'm talking to Shripal. Shripal, I'm coming from easiest. I got an application for the BPO position with us a couple of days ago. So, time to talk.\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      " right now? No ma'am. Alright, Chippa. So like I said I'm calling from easiest we are located in Pune, Hindiwadi Phase 1, cubic sitey park and this is a walk from Hindiwadi location so would that work for you? Yeah. Okay great so we are\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      " We are actually a technical services delivery company, but we are also running a BPO in the travel domain for an international travel domain client basically, so it will be like a voice process and international process kind of a thing. So how much can I notice your overall experience?\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      " I have an overall experience of 4.3 years in non-voice process, international non-voice process, chat and email, not in voice process. Okay, but you are comfortable going for voices.\n",
      "Topics: [['openai', 0.4242607653141022], ['ai', 0.42098575830459595], ['chatgpt', 0.37633663415908813], ['assistant', 0.29333215951919556], ['language', 0.2651599943637848], ['robot', 0.2454492151737213], ['neural', 0.19960856437683105], ['text', 0.19918669760227203], ['learning', 0.19329103827476501], ['intelligence', 0.19080281257629395]]\n",
      "\n",
      " Yeah, I don't have any issues. And how about your excel skills? How would you rate yourself on a scale of 1 to 10? 10 being the highest? 6 to 7. And you're aware about VLOOKUP, HLOOKUP, PIVOT.\n",
      "Topics: [['database', 0.43543002009391785], ['graphql', 0.41655147075653076], ['databases', 0.4079928696155548], ['postgresql', 0.3947259187698364], ['sql', 0.3861182928085327], ['mysql', 0.3533729314804077], ['sqlite', 0.2971377968788147], ['schema', 0.2886453866958618], ['sqlalchemy', 0.25914424657821655], ['sqlite3', 0.25842738151550293]]\n",
      "\n",
      " Oh no about it but I'm ready to learn it as of now I don't have any work on Excel. No work on Excel? Yeah. Okay but maybe you can like learn that and come before the interview right like we might\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      " you know one or two it'll take you hardly like an hour to learn it yeah sure yeah so you can prep for that right so I'll look basic awareness at least okay yeah doing that\n",
      "Topics: [['anytime', 0.547958493232727], ['welcome', 0.42604687809944153], ['assistance', 0.33353191614151], ['helpful', 0.3211679458618164], ['thank', 0.2622171640396118], ['thanks', 0.24634778499603271], ['help', 0.22783665359020233], ['glad', 0.19875562191009521], ['sure', 0.1713462471961975], ['request', 0.1608981043100357]]\n",
      "\n",
      " Okay, how about a CTC current and expected? I have current CTC of 4.90 and I'm expecting 40% increase in that. Yeah, so you were\n",
      "Topics: [['gpus', 0.5102110505104065], ['gpu', 0.46854785084724426], ['motherboard', 0.4229498505592346], ['cpu', 0.4141690731048584], ['hardware', 0.39848506450653076], ['radeon', 0.3514866828918457], ['geforce', 0.34614378213882446], ['upgrading', 0.3420903980731964], ['nvidia', 0.32911717891693115], ['ryzen', 0.32164013385772705]]\n",
      "\n",
      " going with a budget of 4.5 to 5 lakhs maximum no I am currently working at 5 yeah so then I will do it 40% I\n",
      "Topics: [['hvac', 0.39111191034317017], ['remodeling', 0.3354414105415344], ['energy', 0.31473082304000854], ['kwh', 0.3112265467643738], ['housing', 0.30327293276786804], ['efficiency', 0.28826797008514404], ['heating', 0.2839772701263428], ['building', 0.28200939297676086], ['apartment', 0.27025389671325684], ['costs', 0.2518804371356964]]\n",
      "\n",
      "76.42996907234192\n"
     ]
    }
   ],
   "source": [
    "small_whisper, small_whisper_time = get_transcriptions(\"openai/whisper-small.en\", chunks)\n",
    "for transcription in small_whisper:\n",
    "    print(transcription[0])\n",
    "    print(f'Topics: {transcription[1]}')\n",
    "    print()\n",
    "print(small_whisper_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "57d4cb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a925c54ce96d4f7186a372027c9b70f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/2.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70e46543779488e8a43a6bf7f0da49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1abd0faa4294d07ace1a74585c69348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/397 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c082945fb1824cc9b235cfc87cde3c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/351k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a32c06379b4bada28774814ff47d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c59d2934f7d4bde97e86535a15dd939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/254 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12715a414cc4d0ab09b7a45964d12e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6114b83f1e4fa0821e22c017a6a99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee24740268248dfbb732b17aa34f4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25415e5cad9b4573856f36491ee102c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186587c3589f43e49d6c70950dae3064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b6a9f2037c42359b9f1b7bdebada62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab674bb62f84076b8fbc8083aaac946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67b16014ae342b087471c6b0a884511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3098d09a088c44a199e302bd2c30acb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpl  mnry m ci f ezst it a licsn f  bpo positn kits l  ec s0  tim t t\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "ix d m c fm esst vu od n [uny enjdy fas 1 qubic sity pk n diis  wk f dy otn\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "tecnicl ​vic dilivry cyeny by  l  bpo  trv0 dom f intrxn0 trvl domn i skl s b v pr itrns p y  3ig  h 9\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "i have a ovor oll experience of 4.3 ears   in nonws proces internasional nonwproces chad and e mal notn i procesoke bt you ar comfortabl going for woic\n",
      "Topics: [['influenza', 0.3533717393875122], ['flu', 0.3509099781513214], ['panic', 0.30211958289146423], ['symptoms', 0.30014410614967346], ['medical', 0.2752823829650879], ['emergency', 0.26834625005722046], ['calm', 0.2678181529045105], ['diagnosis', 0.252608060836792], ['treatment', 0.21484072506427765], ['healthcare', 0.20278504490852356]]\n",
      "\n",
      "lu and ht exl skils ht atio celf on a scal of 110 1 bn  hst 67 and yor aar abwt ve luk eu lua piwet\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "n aword. b m ed 2 nt j pn  n  wok coex oke bt m b  kn lk lo  letn km bif  intvi\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "b n 1  l  x  dl   9 tl onit  se  n pa  dt rt s  x lx bisi v aist\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "ht ctc e f ctco 4.90 pt 40y vxt  c c 3 i\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "xxy t bzet oi 4.5 x mxmimm  n em m crnly vk t loe0 ilil l 401\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "330.59610390663147\n"
     ]
    }
   ],
   "source": [
    "mms_finetuned, mms_finetuned_time = get_transcriptions(\"facebook/mms-1b-fl102\", chunks)\n",
    "for transcription in mms_finetuned:\n",
    "    print(transcription[0])\n",
    "    print(f'Topics: {transcription[1]}')\n",
    "    print()\n",
    "print(mms_finetuned_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "577fca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ac0de7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Time</th>\n",
       "      <th>Relative Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whisper Large</td>\n",
       "      <td>439.487889</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMS</td>\n",
       "      <td>207.297470</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whisper Small</td>\n",
       "      <td>76.429969</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMS Finetuned</td>\n",
       "      <td>330.596104</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model        Time Relative Accuracy\n",
       "0  Whisper Large  439.487889              high\n",
       "1            MMS  207.297470               low\n",
       "2  Whisper Small   76.429969              high\n",
       "3  MMS Finetuned  330.596104               low"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Model': ['Whisper Large', 'MMS', 'Whisper Small', 'MMS Finetuned'], \n",
    "                   'Time': [openai_time, mms_time, small_whisper_time, mms_finetuned_time],\n",
    "                   'Relative Accuracy': ['high', 'low', 'high', 'low']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9acc2b",
   "metadata": {},
   "source": [
    "Based on the accuracy and time of execution of the model, the Whisper Small model would be the best model to use because of the high accuracy and fast execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a770e37b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
