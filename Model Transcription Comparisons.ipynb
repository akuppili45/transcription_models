{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5cea794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (20230314)\n",
      "Requirement already satisfied: torch in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (1.10.2)\n",
      "Requirement already satisfied: more-itertools in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (8.10.0)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (4.62.3)\n",
      "Requirement already satisfied: numpy in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (1.20.3)\n",
      "Requirement already satisfied: tiktoken==0.3.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (0.3.1)\n",
      "Requirement already satisfied: numba in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from openai-whisper) (0.54.1)\n",
      "Requirement already satisfied: future in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from tiktoken==0.3.1->openai-whisper) (2.26.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from tiktoken==0.3.1->openai-whisper) (2023.6.3)\n",
      "Requirement already satisfied: setuptools in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from numba->openai-whisper) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from numba->openai-whisper) (0.37.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from torch->openai-whisper) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: llama_hub in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (0.0.15)\n",
      "Requirement already satisfied: psutil in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama_hub) (5.8.0)\n",
      "Requirement already satisfied: retrying in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama_hub) (1.3.4)\n",
      "Requirement already satisfied: atlassian-python-api in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama_hub) (3.39.0)\n",
      "Requirement already satisfied: html2text in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama_hub) (2020.1.16)\n",
      "Requirement already satisfied: llama-index>=0.6.9 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama_hub) (0.6.13)\n",
      "Requirement already satisfied: pandas in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (1.3.4)\n",
      "Requirement already satisfied: typing-inspect==0.8.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (0.8.0)\n",
      "Requirement already satisfied: urllib3<2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (1.26.7)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions==4.5.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (4.5.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (0.5.8)\n",
      "Requirement already satisfied: tiktoken in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (0.3.1)\n",
      "Requirement already satisfied: langchain>=0.0.154 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (0.0.154)\n",
      "Requirement already satisfied: numpy in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (1.20.3)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.15 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (2.0.16)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (2023.6.0)\n",
      "Requirement already satisfied: openai>=0.26.4 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from llama-index>=0.6.9->llama_hub) (0.27.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from typing-inspect==0.8.0->llama-index>=0.6.9->llama_hub) (0.4.3)\n",
      "Requirement already satisfied: six in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from atlassian-python-api->llama_hub) (1.12.0)\n",
      "Requirement already satisfied: requests in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from atlassian-python-api->llama_hub) (2.26.0)\n",
      "Requirement already satisfied: oauthlib in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from atlassian-python-api->llama_hub) (3.2.0)\n",
      "Requirement already satisfied: deprecated in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from atlassian-python-api->llama_hub) (1.2.14)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from atlassian-python-api->llama_hub) (1.3.1)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (1.2.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (4.0.2)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (1.10.9)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (3.8.4)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (2.8.4)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (4.62.3)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (6.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->llama-index>=0.6.9->llama_hub) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->llama-index>=0.6.9->llama_hub) (3.19.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->atlassian-python-api->llama_hub) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->atlassian-python-api->llama_hub) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->atlassian-python-api->llama_hub) (2021.10.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sqlalchemy>=2.0.15->llama-index>=0.6.9->llama_hub) (1.1.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from deprecated->atlassian-python-api->llama_hub) (1.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index>=0.6.9->llama_hub) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index>=0.6.9->llama_hub) (2021.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from tiktoken->llama-index>=0.6.9->llama_hub) (2023.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index>=0.6.9->llama_hub) (1.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index>=0.6.9->llama_hub) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index>=0.6.9->llama_hub) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (4.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: filelock in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: fsspec in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement huggingface-cli (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for huggingface-cli\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (1.10.2)\n",
      "Requirement already satisfied: typing_extensions in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (0.21.0)\n",
      "Requirement already satisfied: psutil in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (5.8.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (1.10.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (1.20.3)\n",
      "Requirement already satisfied: pyyaml in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->accelerate) (3.0.4)\n",
      "Requirement already satisfied: typing_extensions in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (2.14.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: packaging in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: xxhash in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.20.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: pandas in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: aiohttp in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: multiprocess in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: filelock in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pydub in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (0.25.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: bertopic in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (0.15.0)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (5.15.0)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (0.5.3)\n",
      "Requirement already satisfied: hdbscan>=0.8.29 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (0.8.33)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (4.62.3)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (2.2.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from bertopic) (0.24.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (1.7.1)\n",
      "Requirement already satisfied: cython<3,>=0.27 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (0.29.24)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2021.3)\n",
      "Requirement already satisfied: packaging in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (21.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (8.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (2.2.0)\n",
      "Requirement already satisfied: nltk in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (3.6.5)\n",
      "Requirement already satisfied: sentencepiece in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.16.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.31.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (1.10.2)\n",
      "Requirement already satisfied: torchvision in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.11.3)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.10)\n",
      "Requirement already satisfied: numba>=0.49 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.54.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: requests in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.26.0)\n",
      "Requirement already satisfied: filelock in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.5.0)\n",
      "Requirement already satisfied: setuptools in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.37.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from packaging->plotly>=4.7.0->bertopic) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.1.5->bertopic) (1.12.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.3.1)\n",
      "Requirement already satisfied: click in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (8.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/adityakuppili/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/adityakuppili/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-whisper\n",
    "!pip install llama_hub\n",
    "!pip install transformers\n",
    "!pip install huggingface-cli\n",
    "!pip install torch\n",
    "!pip install accelerate\n",
    "!pip install datasets\n",
    "!pip install pydub\n",
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c299b4",
   "metadata": {},
   "source": [
    "# Topic extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165e29e",
   "metadata": {},
   "source": [
    "I will be using a library called BERTopic that identifies topics being discussed in a text. The output is a list of various topics with the probability of that topic being mentioned in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cdc991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "topic_model = BERTopic.load(\"davanstrien/chat_topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "032e3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the topics of provided text\n",
    "def get_topics(text):\n",
    "    topic, prob = topic_model.transform(text)\n",
    "    return topic_model.get_topic(topic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d0e317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57eb8f71d93478eb41691e9909e7e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[['chess', 0.531777560710907],\n",
       " ['chessboard', 0.503699779510498],\n",
       " ['practice', 0.35574236512184143],\n",
       " ['strategy', 0.34541815519332886],\n",
       " ['learn', 0.34507590532302856],\n",
       " ['pawn', 0.30584800243377686],\n",
       " ['board', 0.3043401837348938],\n",
       " ['pawns', 0.28188765048980713],\n",
       " ['play', 0.2593632936477661],\n",
       " ['decks', 0.24280010163784027]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topics(\"checkmate is when you win at chess.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072a86c",
   "metadata": {},
   "source": [
    "# Transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5aadc8",
   "metadata": {},
   "source": [
    "The models I will be evaluating are from HuggingFace. I will be inputing the audio file to the HuggingFace models via pipeline() from transformers. The models I will be evaluating are \n",
    "- openai/whisper-large-v2\n",
    "- facebook/mms-1b-all\n",
    "- openai/whisper-small.en\n",
    "- facebook/mms-1b-fl102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7507aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub\n",
    "import time\n",
    "from transformers import pipeline\n",
    "\n",
    "# returns array of transcriptions for each chunk\n",
    "def get_transcriptions(model, chunks):\n",
    "    start_time = time.time()\n",
    "    transform_pipe = pipeline(\"automatic-speech-recognition\", model=model)\n",
    "    transcriptions = []\n",
    "    for i in range(len(chunks)):\n",
    "        transform_pipe_res = transform_pipe(\"./chunk_{}.mp3\".format(i))\n",
    "        transcriptions.append((transform_pipe_res['text'], get_topics(transform_pipe_res['text'])))\n",
    "    end_time = time.time()\n",
    "    return transcriptions, end_time - start_time\n",
    "\n",
    "# splits file into 15 second chunks\n",
    "def getChunks(file):\n",
    "    chunks = []\n",
    "    audio = pydub.AudioSegment.from_mp3(file)\n",
    "    duration = audio.duration_seconds\n",
    "    num_chunks = int(duration / 15)\n",
    "    # Create a list of chunks\n",
    "    chunks = []\n",
    "    for i in range(num_chunks):\n",
    "        start = i * 15000\n",
    "        end = min((i + 1) * 15000, duration * 1000)\n",
    "        chunks.append(audio[start:end])\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk.export(\"chunk_{}.mp3\".format(i), format=\"mp3\")\n",
    "    return chunks\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d0930",
   "metadata": {},
   "source": [
    "I am using the Chetan_BPO Ops Consultant_Recruiter Manjiri.mp3 file for the transcriptions in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353560e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "chunks = getChunks('./Chetan_BPO Ops Consultant_Recruiter Manjiri.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e3f8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bf2af64fde41d89cccc5baa6863049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63606206867f46f6a922eb5127b98022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c424bf49477349929ffe900b13de7d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289faf1fa82545fd977601b8a89be224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015e4b9b9b594168af4afff30716ef21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd196be99f6545e7a75eb21c4359ddee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6399fa5ac94becb667075e7797091c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180d59e9f31f45028102d351c46fa9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f27ebd0f904ece8d5114f9c051a531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello, I am talking to Shripal. Shripal, I am Manjiri. I am calling from E-Zest. I got your application for the BPO position with us couple of days ago. So good time to talk.\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      " right now? Yeah ma'am. Right Shipal, so like I said I am calling from EZest, we are located in Pondek, Injiawadi, Phase 1, Cubix IT Park and this is a work from your location so we would like to work for you. Yeah. Okay, great so we are\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      " we are actually a technical services delivery company but we are also running a BPO in the travel domain for an international travel domain client basically so it will be like a voice process and international process kind of a thing so how much can I notice or overall experience\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      " I have overall experience of 4.3 years in non-voice process international non-voice process chat and email not in voice process okay but you are comfortable going for voice right?\n",
      "Topics: [['openai', 0.4242607653141022], ['ai', 0.42098575830459595], ['chatgpt', 0.37633663415908813], ['assistant', 0.29333215951919556], ['language', 0.2651599943637848], ['robot', 0.2454492151737213], ['neural', 0.19960856437683105], ['text', 0.19918669760227203], ['learning', 0.19329103827476501], ['intelligence', 0.19080281257629395]]\n",
      "\n",
      " Yeah, I don't have any issues. And how about your excel skills? How would you rate yourself on a scale of 1 to 10? 10 being the highest? 6. 6 to 7. And you are aware about VLOOKUP, HLOOKUP, PIVOT?\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      " No, I am ready to learn it. As of now I don't have any work on excel. No work on excel? Yeah. Okay, but maybe you can learn that and come before the interview, right?\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      " it will take you hardly like an hour to learn it. Yeah, sure. Yeah, so you can prep for that, right? So I'll put it as like basic awareness at least. Okay. Yeah. So doing that.\n",
      "Topics: [['openai', 0.4242607653141022], ['ai', 0.42098575830459595], ['chatgpt', 0.37633663415908813], ['assistant', 0.29333215951919556], ['language', 0.2651599943637848], ['robot', 0.2454492151737213], ['neural', 0.19960856437683105], ['text', 0.19918669760227203], ['learning', 0.19329103827476501], ['intelligence', 0.19080281257629395]]\n",
      "\n",
      " ok how about your CTC current and expected? I have current CTC of 4.90 and I am expecting 40% increase in that\n",
      "Topics: [['gpus', 0.5102110505104065], ['gpu', 0.46854785084724426], ['motherboard', 0.4229498505592346], ['cpu', 0.4141690731048584], ['hardware', 0.39848506450653076], ['radeon', 0.3514866828918457], ['geforce', 0.34614378213882446], ['upgrading', 0.3420903980731964], ['nvidia', 0.32911717891693115], ['ryzen', 0.32164013385772705]]\n",
      "\n",
      " actually going with a budget of 4.5 to 5 lakhs maximum. No ma'am I am currently working at 5. Yeah so then I will need 40% higher\n",
      "Topics: [['hvac', 0.39111191034317017], ['remodeling', 0.3354414105415344], ['energy', 0.31473082304000854], ['kwh', 0.3112265467643738], ['housing', 0.30327293276786804], ['efficiency', 0.28826797008514404], ['heating', 0.2839772701263428], ['building', 0.28200939297676086], ['apartment', 0.27025389671325684], ['costs', 0.2518804371356964]]\n",
      "\n",
      "413.72487592697144\n"
     ]
    }
   ],
   "source": [
    "openai_transcriptions, openai_time = get_transcriptions(\"openai/whisper-large-v2\", chunks)\n",
    "for transcription in openai_transcriptions:\n",
    "    print(transcription[0])\n",
    "    print(f'Topics: {transcription[1]}')\n",
    "    print()\n",
    "print(openai_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "084dadd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b2807be0104c2ea7cf40014632ffaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1894317c3d432b8a2e408107edea73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb40efa53c64379815e463ae79a49f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b40890e8f4d49d6b5c908fca4fcbee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3e2d94fe574f938592be6b695150ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852ed4212eb94b7fa0dbd2e8d555ae10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6cff089b8604c5bb2386e89ad1b91e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d76750bb91846a692de385cb5b938a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c00225f123449697dea58f02940e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "igshrepal an mangery iam calling from eas est i gott ar aplication for the bp o position with us couple of das ago so god taime to tak\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      "solike i said i'm calling from easest we are located in puna ingabarry pased one cubic sity park and this is a work for igabary location soto work for yogra\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      "we are actually a tecnical survise's delivery company but we are also running a bpo in the travel domain for in international travel domain clien vasicalli so itl bi lik a voice process an international process kind of a things amagnagv\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      "mr president i have a overall experience of four oi three years in nonwise process international nonwaise process chat and email not in voice process okay but you are comfortable going for voice\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      "aaa obadar exals kills how bad o rator self on a scale of one to ten ten bein the highestand youare aware about we lookup a loku pia\n",
      "Topics: [['poison', 0.41023242473602295], ['chemicals', 0.2576671838760376], ['powder', 0.25158584117889404], ['turpentine', 0.24298548698425293], ['smoke', 0.23245200514793396], ['acid', 0.21897673606872559], ['asbestos', 0.21767115592956543], ['chimney', 0.21686983108520508], ['naphthalene', 0.21119117736816406], ['fireplace', 0.19657978415489197]]\n",
      "\n",
      "no aor but i'm ready to learn it as  nowi don't avan wr maybe you can lak lawn dt and come before the interview\n",
      "Topics: [['chess', 0.531777560710907], ['chessboard', 0.503699779510498], ['practice', 0.35574236512184143], ['strategy', 0.34541815519332886], ['learn', 0.34507590532302856], ['pawn', 0.30584800243377686], ['board', 0.3043401837348938], ['pawns', 0.28188765048980713], ['play', 0.2593632936477661], ['decks', 0.24280010163784027]]\n",
      "\n",
      "b yo in one ot o itl take you hadly alike a nar tool on itya so you can prape for that rat so oil put it as laike basic awarness at leastg\n",
      "Topics: [['chess', 0.531777560710907], ['chessboard', 0.503699779510498], ['practice', 0.35574236512184143], ['strategy', 0.34541815519332886], ['learn', 0.34507590532302856], ['pawn', 0.30584800243377686], ['board', 0.3043401837348938], ['pawns', 0.28188765048980713], ['play', 0.2593632936477661], ['decks', 0.24280010163784027]]\n",
      "\n",
      "i have carent ctc a fourpint nine zo an aiam exspecting a forty versant incrisein that    s\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "ll ging with a budget of    mai a i  a i am currently working a ia s a  will  a t aca\n",
      "Topics: [['hvac', 0.39111191034317017], ['remodeling', 0.3354414105415344], ['energy', 0.31473082304000854], ['kwh', 0.3112265467643738], ['housing', 0.30327293276786804], ['efficiency', 0.28826797008514404], ['heating', 0.2839772701263428], ['building', 0.28200939297676086], ['apartment', 0.27025389671325684], ['costs', 0.2518804371356964]]\n",
      "\n",
      "209.30714201927185\n"
     ]
    }
   ],
   "source": [
    "mms_transcriptions, mms_time = get_transcriptions(\"facebook/mms-1b-all\", chunks)\n",
    "for transcription in mms_transcriptions:\n",
    "    print(transcription[0])\n",
    "    print(f'Topics: {transcription[1]}')\n",
    "    print()\n",
    "print(mms_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f740188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14acd404ecb64f6989a1f11c4f19188e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23015efb2a44baa860d6212c3c2fe2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290232a4f7fd4683911419128361515c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55afa0b165a14357b13417dd9be4e8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ff3caed67e482bbadfb90dbb68f6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3274ce0b427744079b84cbb64ed89bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcf21cb0c7348d2a53ee3f0b1e517f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548243d8948441b9b72982672e70537d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330c359ff46940ca9ce136dbe27df7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello, I'm talking to Shripal. Shripal, I'm coming from easiest. I got an application for the BPO position with us a couple of days ago. So, time to talk.\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      " right now? No ma'am. Alright, Chippa. So like I said I'm calling from easiest we are located in Pune, Hindiwadi Phase 1, cubic sitey park and this is a walk from Hindiwadi location so would that work for you? Yeah. Okay great so we are\n",
      "Topics: [['letter', 0.4082227051258087], ['sincerely', 0.31927675008773804], ['regards', 0.28891339898109436], ['email', 0.2867659330368042], ['dear', 0.2751607298851013], ['polite', 0.26389122009277344], ['colleague', 0.2621317207813263], ['apologize', 0.255462646484375], ['hi', 0.2506524920463562], ['meeting', 0.21596617996692657]]\n",
      "\n",
      " We are actually a technical services delivery company, but we are also running a BPO in the travel domain for an international travel domain client basically, so it will be like a voice process and international process kind of a thing. So how much can I notice your overall experience?\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      " I have an overall experience of 4.3 years in non-voice process, international non-voice process, chat and email, not in voice process. Okay, but you are comfortable going for voices.\n",
      "Topics: [['openai', 0.4242607653141022], ['ai', 0.42098575830459595], ['chatgpt', 0.37633663415908813], ['assistant', 0.29333215951919556], ['language', 0.2651599943637848], ['robot', 0.2454492151737213], ['neural', 0.19960856437683105], ['text', 0.19918669760227203], ['learning', 0.19329103827476501], ['intelligence', 0.19080281257629395]]\n",
      "\n",
      " Yeah, I don't have any issues. And how about your excel skills? How would you rate yourself on a scale of 1 to 10? 10 being the highest? 6 to 7. And you're aware about VLOOKUP, HLOOKUP, PIVOT.\n",
      "Topics: [['database', 0.43543002009391785], ['graphql', 0.41655147075653076], ['databases', 0.4079928696155548], ['postgresql', 0.3947259187698364], ['sql', 0.3861182928085327], ['mysql', 0.3533729314804077], ['sqlite', 0.2971377968788147], ['schema', 0.2886453866958618], ['sqlalchemy', 0.25914424657821655], ['sqlite3', 0.25842738151550293]]\n",
      "\n",
      " Oh no about it but I'm ready to learn it as of now I don't have any work on Excel. No work on Excel? Yeah. Okay but maybe you can like learn that and come before the interview right like we might\n",
      "Topics: [['devops', 0.43932032585144043], ['development', 0.3638766407966614], ['developers', 0.334741473197937], ['industry', 0.31386125087738037], ['develop', 0.3117571473121643], ['job', 0.2705976068973541], ['build', 0.2619786560535431], ['skills', 0.24939802289009094], ['resume', 0.24679487943649292], ['work', 0.2347835898399353]]\n",
      "\n",
      " you know one or two it'll take you hardly like an hour to learn it yeah sure yeah so you can prep for that right so I'll look basic awareness at least okay yeah doing that\n",
      "Topics: [['anytime', 0.547958493232727], ['welcome', 0.42604687809944153], ['assistance', 0.33353191614151], ['helpful', 0.3211679458618164], ['thank', 0.2622171640396118], ['thanks', 0.24634778499603271], ['help', 0.22783665359020233], ['glad', 0.19875562191009521], ['sure', 0.1713462471961975], ['request', 0.1608981043100357]]\n",
      "\n",
      " Okay, how about a CTC current and expected? I have current CTC of 4.90 and I'm expecting 40% increase in that. Yeah, so you were\n",
      "Topics: [['gpus', 0.5102110505104065], ['gpu', 0.46854785084724426], ['motherboard', 0.4229498505592346], ['cpu', 0.4141690731048584], ['hardware', 0.39848506450653076], ['radeon', 0.3514866828918457], ['geforce', 0.34614378213882446], ['upgrading', 0.3420903980731964], ['nvidia', 0.32911717891693115], ['ryzen', 0.32164013385772705]]\n",
      "\n",
      " going with a budget of 4.5 to 5 lakhs maximum no I am currently working at 5 yeah so then I will do it 40% I\n",
      "Topics: [['hvac', 0.39111191034317017], ['remodeling', 0.3354414105415344], ['energy', 0.31473082304000854], ['kwh', 0.3112265467643738], ['housing', 0.30327293276786804], ['efficiency', 0.28826797008514404], ['heating', 0.2839772701263428], ['building', 0.28200939297676086], ['apartment', 0.27025389671325684], ['costs', 0.2518804371356964]]\n",
      "\n",
      "78.56740927696228\n"
     ]
    }
   ],
   "source": [
    "small_whisper, small_whisper_time = get_transcriptions(\"openai/whisper-small.en\", chunks)\n",
    "for transcription in small_whisper:\n",
    "    print(transcription[0])\n",
    "    print(f'Topics: {transcription[1]}')\n",
    "    print()\n",
    "print(small_whisper_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3091fe99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bc69a5da0948dc9c576368402fea48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc86041870f34c72b05ea03ffea196de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9167bf42bdcf477da01a1db0a958f5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d9fde54d274d27b819ca5170800787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7456fb38bc584b0abb769502c62f2ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53be420f0eab4b45b4c8541e3bf28b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554d5a97dfc14b7181d92d4c7a2dcf00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8f824c632444c3b44ad6a868616f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598e48e996224bb9b0bf34a89bf1f16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpl  mnry m ci f ezst it a licsn f  bpo positn kits l  ec s0  tim t t\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "ix d m c fm esst vu od n [uny enjdy fas 1 qubic sity pk n diis  wk f dy otn\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "tecnicl vic dilivry cyeny by  l  bpo  trv0 dom f intrxn0 trvl domn i skl s b v pr itrns p y  3ig  h 9\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "i have a ovor oll experience of 4.3 ears   in nonws proces internasional nonwproces chad and e mal notn i procesoke bt you ar comfortabl going for woic\n",
      "Topics: [['influenza', 0.3533717393875122], ['flu', 0.3509099781513214], ['panic', 0.30211958289146423], ['symptoms', 0.30014410614967346], ['medical', 0.2752823829650879], ['emergency', 0.26834625005722046], ['calm', 0.2678181529045105], ['diagnosis', 0.252608060836792], ['treatment', 0.21484072506427765], ['healthcare', 0.20278504490852356]]\n",
      "\n",
      "lu and ht exl skils ht atio celf on a scal of 110 1 bn  hst 67 and yor aar abwt ve luk eu lua piwet\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "n aword. b m ed 2 nt j pn  n  wok coex oke bt m b  kn lk lo  letn km bif  intvi\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "b n 1  l  x  dl   9 tl onit  se  n pa  dt rt s  x lx bisi v aist\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "ht ctc e f ctco 4.90 pt 40y vxt  c c 3 i\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "xxy t bzet oi 4.5 x mxmimm  n em m crnly vk t loe0 ilil l 401\n",
      "Topics: [['ascii', 0.6627934575080872], ['glyphs', 0.5676862001419067], ['hiragana', 0.4461706280708313], ['art', 0.44102251529693604], ['font', 0.4020988345146179], ['kanji', 0.3987252712249756], ['text', 0.3903907537460327], ['characters', 0.35387447476387024], ['graphics', 0.34570205211639404], ['code', 0.32968831062316895]]\n",
      "\n",
      "212.30901503562927\n"
     ]
    }
   ],
   "source": [
    "mms_finetuned, mms_finetuned_time = get_transcriptions(\"facebook/mms-1b-fl102\", chunks)\n",
    "for transcription in mms_finetuned:\n",
    "    print(transcription[0])\n",
    "    print(f'Topics: {transcription[1]}')\n",
    "    print()\n",
    "print(mms_finetuned_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48b239df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a46803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Time to Transcript in Seconds</th>\n",
       "      <th>Relative Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Open AI Whisper Large</td>\n",
       "      <td>413.724876</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook MMS</td>\n",
       "      <td>209.307142</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Open AI Whisper Small</td>\n",
       "      <td>78.567409</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook MMS Finetuned</td>\n",
       "      <td>212.309015</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Time to Transcript in Seconds Relative Accuracy\n",
       "0   Open AI Whisper Large                     413.724876              high\n",
       "1            Facebook MMS                     209.307142               low\n",
       "2   Open AI Whisper Small                      78.567409              high\n",
       "3  Facebook MMS Finetuned                     212.309015               low"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Model': ['Open AI Whisper Large', 'Facebook MMS', 'Open AI Whisper Small', 'Facebook MMS Finetuned'], \n",
    "                   'Time to Transcript in Seconds': [openai_time, mms_time, small_whisper_time, mms_finetuned_time],\n",
    "                   'Relative Accuracy': ['high', 'low', 'high', 'low']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0443f6",
   "metadata": {},
   "source": [
    "Based on the accuracy and time of execution of the model, the Whisper Small model would be the best model to use because of the high accuracy and fast execution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
